{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "import recbole.model.sequential_recommender as seq_models\n",
    "import recbole.trainer as trainers\n",
    "from recbole.utils import init_seed, init_logger\n",
    "\n",
    "logger = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'coveo'\n",
    "data_path = f'./data/{dataset_name}'\n",
    "dataset = f'{dataset_name}_processed_view_train_full_test_stacked.inter'\n",
    "dataset_train = f'{dataset_name}_processed_view_train_full.inter'\n",
    "dataset_test = f'{dataset_name}_processed_view_test_augmented.inter'\n",
    "# Model parameters\n",
    "model_params = {\n",
    "    'coveo': {\n",
    "        \"model\": \"Gru4Rec\",\n",
    "        \"loss\": \"CE\",\n",
    "        \"learner\": \"adagrad\",\n",
    "        \"embedding_size\": 512,\n",
    "        \"hidden_size\": 512,\n",
    "        \"num_layers\": 1,\n",
    "        \"train_batch_size\": 32,\n",
    "        \"eval_batch_size\": 2048,\n",
    "        \"dropout_prob\": 0.4, #embedding dropout\n",
    "        \"lr\": 0.03,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inter_files(parameter_dict:dict):\n",
    "    for fn in os.listdir(parameter_dict['data_path']):\n",
    "        if fn.endswith('.tsv'):\n",
    "            file_path = os.path.join(parameter_dict['data_path'], fn)\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                headers = lines[0].split('\\t')\n",
    "                headers = [h.replace('\\n', '') + parameter_dict['column_postfix'][h.replace('\\n', '')] for h in headers]\n",
    "                lines[0] = '\\t'.join(headers) + '\\n'\n",
    "            with open(file_path, 'w') as f:\n",
    "                f.writelines(lines)\n",
    "            os.rename(file_path, file_path.replace('.tsv', '.inter'))\n",
    "\n",
    "def stack_train_test_datasets(data_path:str, dataset_train:str, dataset_test:str):\n",
    "    ds_stacked = []\n",
    "    for ds_name in [dataset_train, dataset_test]:\n",
    "        data = pd.read_csv(os.path.join(data_path, ds_name), sep='\\t')\n",
    "        print(data.shape)\n",
    "        ds_stacked.append(data)\n",
    "    ds_stacked = pd.concat(ds_stacked, axis=0)\n",
    "    ds_stacked.to_csv(os.path.join(data_path, dataset), sep='\\t', index=False)\n",
    "    print(\"stacked_shape\", ds_stacked.shape)\n",
    "\n",
    "def augment_session_data(parameter_dict:dict, data_path:str, dataset_test:str):\n",
    "    user_id = parameter_dict['USER_ID_FIELD']\n",
    "    user_id += parameter_dict['column_postfix'][user_id] \n",
    "    item_id = parameter_dict['ITEM_ID_FIELD']\n",
    "    item_id += parameter_dict['column_postfix'][item_id]\n",
    "    timestamp = parameter_dict['TIME_FIELD']\n",
    "    timestamp += parameter_dict['column_postfix'][timestamp]\n",
    "\n",
    "    data = pd.read_csv(os.path.join(data_path, dataset_test.replace('_augmented', '')), sep='\\t')\n",
    "    print(\"original_shape\", data.shape, \"orignal_sessions\", data[user_id].nunique())\n",
    "    data = data.sort_values(by=[user_id, timestamp])\n",
    "    new_data = []\n",
    "    i = 0\n",
    "    for session_id, session_data in data.groupby(user_id):\n",
    "        for i in range(1, len(session_data)):\n",
    "            aug_data = session_data.iloc[:i+1].copy()\n",
    "            aug_data[user_id] = aug_data[user_id].apply(lambda x: f\"{x}_aug_{i-1}\")\n",
    "            new_data.append(aug_data)\n",
    "    new_data = pd.concat(new_data, axis=0)\n",
    "    new_data.to_csv(os.path.join(data_path, dataset_test), sep='\\t', index=False)\n",
    "    print(\"augmented_shape\", new_data.shape, \"augmented_sessions\", new_data[user_id].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_shape (52501, 3) orignal_sessions 7748\n",
      "augmented_shape (465904, 3) augmented_sessions 44753\n",
      "(1411113, 3)\n",
      "(465904, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05 Sep 14:19    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ./data/coveo/coveo_processed_view_train_full_test_stacked.inter\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 5\n",
      "train_batch_size = 32\n",
      "learner = adagrad\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacked_shape (1877017, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "eval_step = 5\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'TS': {'train_path': './data/coveo/coveo_processed_view_train_full.inter', 'test_path': './data/coveo/coveo_processed_view_test_augmented.inter'}}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'Hit']\n",
      "topk = [1, 5, 10, 20]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 2048\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = SessionId\n",
      "ITEM_ID_FIELD = ItemId\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = Time\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['SessionId', 'ItemId', 'Time']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [1,inf)\n",
      "item_inter_num_interval = [1,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 512\n",
      "hidden_size = 512\n",
      "num_layers = 1\n",
      "dropout_prob = 0.4\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "column_postfix = {'SessionId': ':token', 'ItemId': ':token', 'Time': ':float'}\n",
      "neg_sampling = None\n",
      "loss = CE\n",
      "lr = 0.03\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = ./data/coveo/coveo_processed_view_train_full_test_stacked.inter\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 5\n",
      "train_batch_size = 32\n",
      "learner = adagrad\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 5\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'TS': {'train_path': './data/coveo/coveo_processed_view_train_full.inter', 'test_path': './data/coveo/coveo_processed_view_test_augmented.inter'}}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'Hit']\n",
      "topk = [1, 5, 10, 20]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 2048\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = SessionId\n",
      "ITEM_ID_FIELD = ItemId\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = Time\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['SessionId', 'ItemId', 'Time']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [1,inf)\n",
      "item_inter_num_interval = [1,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = False\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 512\n",
      "hidden_size = 512\n",
      "num_layers = 1\n",
      "dropout_prob = 0.4\n",
      "loss_type = CE\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "column_postfix = {'SessionId': ':token', 'ItemId': ':token', 'Time': ':float'}\n",
      "neg_sampling = None\n",
      "loss = CE\n",
      "lr = 0.03\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "valid_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "user_id = 'SessionId'\n",
    "item_id = 'ItemId'\n",
    "timestamp = 'Time'\n",
    "parameter_dict = {\n",
    "    'data_path': data_path,\n",
    "    'dataset': dataset,\n",
    "    'USER_ID_FIELD': user_id,\n",
    "    'ITEM_ID_FIELD': item_id,\n",
    "    'TIME_FIELD': timestamp,\n",
    "    'column_postfix':{\n",
    "        user_id: ':token',\n",
    "        item_id: ':token',\n",
    "        timestamp: ':float'\n",
    "    },\n",
    "    # Preproc\n",
    "    'user_inter_num_interval': \"[1,inf)\",\n",
    "    'item_inter_num_interval': \"[1,inf)\",\n",
    "    'load_col': {'inter': [user_id, item_id, timestamp]},\n",
    "    \n",
    "    # Train\n",
    "    'train_neg_sample_args': None, # XE does not support neg sampling\n",
    "    'epochs': epochs,\n",
    "    'eval_step': epochs,\n",
    "\n",
    "    # Eval\n",
    "    'neg_sampling': None,\n",
    "    'shuffle': False,\n",
    "    'eval_args': {\n",
    "        'split': {\n",
    "            'TS': {\n",
    "                'train_path': os.path.join(data_path, dataset_train),\n",
    "                'test_path': os.path.join(data_path, dataset_test),}\n",
    "            },\n",
    "        'group_by': 'user',\n",
    "        'order': 'TO',\n",
    "        'mode': 'full',\n",
    "        },\n",
    "    'topk': [1,5,10,20],\n",
    "    'metrics': ['Recall', 'MRR', 'Hit'],\n",
    "}\n",
    "parameter_dict.update(model_params[dataset_name])\n",
    "\n",
    "create_inter_files(parameter_dict)\n",
    "augment_session_data(parameter_dict, data_path, dataset_test)\n",
    "stack_train_test_datasets(data_path, dataset_train, dataset_test)\n",
    "\n",
    "config = Config(model='GRU4Rec', config_dict=parameter_dict) #dataset=\"recbox_data\"\n",
    "\n",
    "# init random seed\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "if logger is None:\n",
    "    # logger initialization\n",
    "    init_logger(config)\n",
    "    logger = getLogger()\n",
    "    # Create handlers\n",
    "    c_handler = logging.StreamHandler()\n",
    "    c_handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(c_handler)\n",
    "\n",
    "    # write config info into log\n",
    "logger.info(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05 Sep 14:20    INFO  coveo_processed_view_train_full_test_stacked.inter\n",
      "The number of users: 210427\n",
      "Average actions of users: 8.920081168676875\n",
      "The number of items: 10869\n",
      "Average actions of items: 172.71043430253957\n",
      "The number of inters: 1877017\n",
      "The sparsity of the dataset: 99.91793137567123%\n",
      "Remain Fields: ['SessionId', 'ItemId', 'Time']\n",
      "coveo_processed_view_train_full_test_stacked.inter\n",
      "The number of users: 210427\n",
      "Average actions of users: 8.920081168676875\n",
      "The number of items: 10869\n",
      "Average actions of items: 172.71043430253957\n",
      "The number of inters: 1877017\n",
      "The sparsity of the dataset: 99.91793137567123%\n",
      "Remain Fields: ['SessionId', 'ItemId', 'Time']\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SessionId</th>\n",
       "      <th>ItemId</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.544228e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.544228e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.544229e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.544229e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.544229e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SessionId  ItemId          Time\n",
       "0          1       1  1.544228e+12\n",
       "1          1       2  1.544228e+12\n",
       "2          1       3  1.544229e+12\n",
       "3          1       4  1.544229e+12\n",
       "4          1       5  1.544229e+12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.inter_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changed feat format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05 Sep 14:21    INFO  time based split, from prepared file, train_path=[./data/coveo/coveo_processed_view_train_full.inter], test_path=[./data/coveo/coveo_processed_view_test_augmented.inter]\n",
      "time based split, from prepared file, train_path=[./data/coveo/coveo_processed_view_train_full.inter], test_path=[./data/coveo/coveo_processed_view_test_augmented.inter]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(465904, 3) (1411113, 3)\n",
      "(465904, 3) (1411113, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05 Sep 14:21    INFO  [Training]: train_batch_size = [32] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [32] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "05 Sep 14:21    INFO  [Evaluation]: eval_batch_size = [2048] eval_args: [{'split': {'TS': {'train_path': './data/coveo/coveo_processed_view_train_full.inter', 'test_path': './data/coveo/coveo_processed_view_test_augmented.inter'}}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n",
      "[Evaluation]: eval_batch_size = [2048] eval_args: [{'split': {'TS': {'train_path': './data/coveo/coveo_processed_view_train_full.inter', 'test_path': './data/coveo/coveo_processed_view_test_augmented.inter'}}, 'order': 'TO', 'group_by': 'user', 'mode': {'valid': 'full', 'test': 'full'}}]\n"
     ]
    }
   ],
   "source": [
    "# dataset splitting\n",
    "train_data, _, test_data = data_preparation(config, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05 Sep 14:21    INFO  GRU4Rec(\n",
      "  (item_embedding): Embedding(10869, 512, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (gru_layers): GRU(512, 512, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 7400448\n",
      "GRU4Rec(\n",
      "  (item_embedding): Embedding(10869, 512, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (gru_layers): GRU(512, 512, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 7400448\n",
      "05 Sep 14:23    INFO  epoch 0 training [time: 97.39s, train loss: 8.8068]\n",
      "epoch 0 training [time: 97.39s, train loss: 8.8068]\n",
      "05 Sep 14:25    INFO  epoch 1 training [time: 98.58s, train loss: 8.5009]\n",
      "epoch 1 training [time: 98.58s, train loss: 8.5009]\n",
      "05 Sep 14:26    INFO  epoch 2 training [time: 98.40s, train loss: 8.3896]\n",
      "epoch 2 training [time: 98.40s, train loss: 8.3896]\n",
      "05 Sep 14:28    INFO  epoch 3 training [time: 98.01s, train loss: 8.3227]\n",
      "epoch 3 training [time: 98.01s, train loss: 8.3227]\n",
      "05 Sep 14:29    INFO  epoch 4 training [time: 97.74s, train loss: 8.2762]\n",
      "epoch 4 training [time: 97.74s, train loss: 8.2762]\n",
      "05 Sep 14:30    INFO  epoch 4 evaluating [time: 3.15s, valid_score: 0.009500]\n",
      "epoch 4 evaluating [time: 3.15s, valid_score: 0.009500]\n",
      "05 Sep 14:30    INFO  valid result: \n",
      "recall@1 : 0.0038    recall@5 : 0.0158    recall@10 : 0.0286    recall@20 : 0.0473    mrr@1 : 0.0038    mrr@5 : 0.0079    mrr@10 : 0.0095    mrr@20 : 0.0108    hit@1 : 0.0038    hit@5 : 0.0158    hit@10 : 0.0286    hit@20 : 0.0473\n",
      "valid result: \n",
      "recall@1 : 0.0038    recall@5 : 0.0158    recall@10 : 0.0286    recall@20 : 0.0473    mrr@1 : 0.0038    mrr@5 : 0.0079    mrr@10 : 0.0095    mrr@20 : 0.0108    hit@1 : 0.0038    hit@5 : 0.0158    hit@10 : 0.0286    hit@20 : 0.0473\n",
      "05 Sep 14:30    INFO  Saving current: saved/GRU4Rec-Sep-05-2023_14-21-47.pth\n",
      "Saving current: saved/GRU4Rec-Sep-05-2023_14-21-47.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. epoch time (s) 98.02\n"
     ]
    }
   ],
   "source": [
    "# model loading and initialization\n",
    "model_gru4rec = seq_models.GRU4Rec(config, train_data.dataset).to(config['device'])\n",
    "logger.info(model_gru4rec)\n",
    "\n",
    "# trainer loading and initialization\n",
    "trainer = trainers.Trainer(config, model_gru4rec)\n",
    "\n",
    "# model training\n",
    "best_valid_score, best_valid_result = trainer.fit(train_data=train_data, valid_data=test_data, show_progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
